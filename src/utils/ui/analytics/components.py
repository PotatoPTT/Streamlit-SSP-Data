"""
Gerenciamento de fluxos de interface para an√°lises preditivas.
"""

import streamlit as st
import pandas as pd
import time
from utils.config.logging import get_logger

logger = get_logger("ANALYTICS_UI")


def render_date_filters(df_anos, df_meses_por_ano,
                        default_ano_inicio=None, default_mes_inicio=None,
                        default_ano_fim=None, default_mes_fim=None):
    """Renderiza os filtros de data da interface com valores padr√£o opcionais."""
    from utils.ui.analytics.utils import get_meses_mapping, get_available_months_for_year, filter_end_months

    meses_map, meses_map_inv = get_meses_mapping()
    anos_list = df_anos["ano"].sort_values(ascending=False).tolist()

    if default_ano_inicio not in anos_list:
        default_ano_inicio = anos_list[0] if anos_list else None

    st.markdown("##### Per√≠odo da An√°lise")
    col_start, col_end = st.columns(2)

    with col_start:
        ano_inicio_index = anos_list.index(
            default_ano_inicio) if default_ano_inicio in anos_list else 0
        ano_inicio = st.selectbox(
            "Ano de In√≠cio", anos_list, index=ano_inicio_index)
        meses_disponiveis_inicio = get_available_months_for_year(
            df_meses_por_ano, ano_inicio)
        meses_nomes_inicio = [meses_map_inv[m]
                              for m in meses_disponiveis_inicio]
        if default_mes_inicio not in meses_nomes_inicio:
            mes_inicio_index = 0
        else:
            mes_inicio_index = meses_nomes_inicio.index(default_mes_inicio)
        mes_inicio = st.selectbox(
            "M√™s de In√≠cio", meses_nomes_inicio, index=mes_inicio_index)

    with col_end:
        anos_fim_disponiveis = [ano for ano in anos_list if ano >= ano_inicio]
        if default_ano_fim not in anos_fim_disponiveis:
            ano_fim_index = 0
        else:
            ano_fim_index = anos_fim_disponiveis.index(default_ano_fim)
        ano_fim = st.selectbox("Ano de Fim", anos_fim_disponiveis,
                               index=ano_fim_index)

        meses_disponiveis_fim = get_available_months_for_year(
            df_meses_por_ano, ano_fim)
        mes_inicio_num = meses_map[mes_inicio]
        meses_fim_filtrados = filter_end_months(
            meses_disponiveis_fim, ano_fim, ano_inicio, mes_inicio_num + 1)

        meses_nomes_fim = [meses_map_inv[m] for m in meses_fim_filtrados]
        if default_mes_fim in meses_nomes_fim:
            mes_fim_index = meses_nomes_fim.index(default_mes_fim)
        else:
            mes_fim_index = len(meses_nomes_fim) - 1 if meses_nomes_fim else 0
        mes_fim = st.selectbox("M√™s de Fim", meses_nomes_fim,
                               index=mes_fim_index)

    return ano_inicio, mes_inicio, ano_fim, mes_fim


def render_location_filter(df_regioes, default_regiao=None):
    """Renderiza o filtro de localiza√ß√£o com valor padr√£o opcional."""
    st.markdown("##### Localiza√ß√£o")
    # Filtrar regi√µes para excluir "Capital"
    df_regioes_filtrado = df_regioes[df_regioes["nome"] != "Capital"]
    regioes_list = ["Todas"] + df_regioes_filtrado["nome"].tolist()
    if default_regiao not in regioes_list:
        default_index = 0
    else:
        default_index = regioes_list.index(default_regiao)
    return st.selectbox("Regi√£o", regioes_list, index=default_index)


def render_crime_filter(default_crime=None):
    """Renderiza o filtro de tipo de crime com valor padr√£o opcional."""
    from utils.ui.analytics.utils import get_crimes_list
    st.markdown("##### Tipo de Crime")
    crimes_list = get_crimes_list()
    if default_crime not in crimes_list:
        default_index = 0 if crimes_list else None
    else:
        default_index = crimes_list.index(default_crime)
    if crimes_list:
        return st.selectbox("Natureza do Crime", crimes_list, index=default_index)
    st.warning("Nenhum crime dispon√≠vel para sele√ß√£o.")
    return None


def render_method_selector(solicit_k, solicit_d):
    """Renderiza o seletor de m√©todo quando h√° solicita√ß√µes existentes."""
    from utils.ui.analytics.utils import get_status_label

    options = [
        ('kmeans', get_status_label(solicit_k, 'K-Means')),
        ('kdba', get_status_label(solicit_d, 'K-DBA'))
    ]

    # Escolhe por padr√£o o K-Means se estiver conclu√≠do, sen√£o o primeiro dispon√≠vel
    default = 0
    if solicit_k and solicit_k['status'] == 'CONCLUIDO':
        default = 0
    elif solicit_d and solicit_d['status'] == 'CONCLUIDO':
        default = 1

    choice = st.selectbox('Modelo dispon√≠vel', [
                          o[1] for o in options], index=default)
    selected_method = ['kmeans', 'kdba'][[o[1] for o in options].index(choice)]
    selected_solicit = solicit_k if selected_method == 'kmeans' else solicit_d

    return selected_method, selected_solicit


def handle_completed_model(selected_method, selected_solicit, params, db):
    """Gerencia o fluxo quando um modelo est√° conclu√≠do."""
    from utils.ui.analytics.utils import (
        get_model_filename, load_model_from_file_or_db,
        fetch_data_for_model_cached, prepare_municipalities_table
    )
    from utils.visualization.plots import (
        display_model_metrics, plot_time_series_by_cluster, plot_map_by_cluster,
        plot_centroids_comparison, plot_silhouette_by_cluster
    )

    model_filename = get_model_filename(selected_method, params)
    if not model_filename:
        st.error(
            "Artefato do modelo n√£o encontrado (valor vazio). Considere gerar o modelo novamente.")
        return

    try:
        model_data = load_model_from_file_or_db(
            model_filename, selected_solicit, db)
    except FileNotFoundError as e:
        st.error(f"Erro ao carregar modelo: {e}")
        return
    except Exception as e:
        st.error(f"Erro inesperado ao carregar modelo: {e}")
        return

    model = model_data['model']
    scaler_type = model_data.get('scaler', 'unknown')
    k = model_data.get('k')
    silhouette = model_data.get('silhouette')  # Pegar silhouette do modelo
    cleaning_stats = model_data.get('cleaning_stats', {})
    city_names_trained = model_data.get('city_names', [])

    # Exibir estat√≠sticas de limpeza de dados (do Clustering Project)
    if cleaning_stats:
        st.markdown("#### üìä Estat√≠sticas de Prepara√ß√£o dos Dados")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "Munic√≠pios Originais", 
                cleaning_stats.get('original_municipalities', 'N/A')
            )
        
        with col2:
            removed_null = cleaning_stats.get('removed_null_series', 0)
            st.metric(
                "S√©ries Removidas (Nulas)", 
                removed_null
            )
        
        with col3:
            final_mun = cleaning_stats.get('final_municipalities', 'N/A')
            st.metric(
                "Munic√≠pios Finais", 
                final_mun
            )
        
        # Exibir detalhes adicionais
        with st.expander("‚ÑπÔ∏è Detalhes da limpeza de dados"):
            removed_nan = cleaning_stats.get('removed_nan_series', 0)
            removed_null = cleaning_stats.get('removed_null_series', 0)
            
            st.markdown(f"""
            - **Per√≠odos temporais analisados:** {cleaning_stats.get('original_periods', 'N/A')}
            - **Normaliza√ß√£o utilizada:** {scaler_type.upper() if scaler_type else 'Desconhecido'}
            - **Valores inv√°lidos encontrados:** {'Sim' if cleaning_stats.get('had_invalid_values') else 'N√£o'}
            - **Total de s√©ries descartadas:** {removed_nan + removed_null}
            """)
            
            if removed_nan > 0 or removed_null > 0:
                st.info(
                    f"‚ö†Ô∏è Foram descartadas {removed_nan + removed_null} s√©ries temporais que n√£o "
                    f"atendiam aos crit√©rios de qualidade (s√©ries com NaN ou completamente nulas)."
                )

    # Exibir m√©tricas do modelo
    display_model_metrics(silhouette, k)

    # Buscar dados e gerar visualiza√ß√µes (usando vers√£o cacheada)
    import json
    time_series_df_all = fetch_data_for_model_cached(
        json.dumps(params, sort_keys=True))

    if not time_series_df_all.empty:
        # IMPORTANTE: Filtrar apenas os munic√≠pios que foram usados no treinamento
        # O modelo foi treinado com dados limpos (sem s√©ries nulas)
        if city_names_trained:
            # Filtrar apenas munic√≠pios que est√£o na lista de treinamento
            time_series_df = time_series_df_all[
                time_series_df_all.index.isin(city_names_trained)
            ].copy()
            
            if len(time_series_df) != len(city_names_trained):
                st.warning(
                    f"‚ö†Ô∏è Aten√ß√£o: Esperavam-se {len(city_names_trained)} munic√≠pios do treinamento, "
                    f"mas apenas {len(time_series_df)} foram encontrados no banco."
                )
                logger.warning(
                    f"Munic√≠pios treinados: {len(city_names_trained)}, "
                    f"Munic√≠pios encontrados: {len(time_series_df)}"
                )
        else:
            st.warning("‚ö†Ô∏è Lista de munic√≠pios do treinamento n√£o encontrada no modelo. Usando todos os dados.")
            time_series_df = time_series_df_all.copy()
        
        if time_series_df.empty:
            st.error("Nenhum dado v√°lido encontrado para os munic√≠pios do treinamento.")
            return
            
        st.info(f"üìä Visualizando {len(time_series_df)} munic√≠pios (usados no treinamento)")
        
        # Preparar dados para predi√ß√£o
        # 1. Converter para formato tslearn [n_samples, n_timesteps, 1]
        from tslearn.utils import to_time_series_dataset
        from sklearn.preprocessing import RobustScaler
        import numpy as np
        
        try:
            # Converter para formato tslearn
            X_tslearn = to_time_series_dataset(time_series_df.values)
            
            # Normalizar da mesma forma que no treinamento
            X_2d = X_tslearn.squeeze()
            X_scaled_2d = np.array([
                RobustScaler().fit_transform(X_2d[i, :].reshape(-1, 1)).flatten() 
                for i in range(X_2d.shape[0])
            ])
            X_scaled = X_scaled_2d.reshape(X_tslearn.shape)
            
            # Fazer predi√ß√£o
            labels = model.predict(X_scaled)
            
        except Exception as err:
            st.error(f"Erro ao prever clusters com o modelo carregado: {err}")
            logger.exception(f"Erro na predi√ß√£o: {err}")
            return

        time_series_df_with_labels = time_series_df.copy()
        time_series_df_with_labels['cluster'] = labels

        # Plotar mapa de clusters
        plot_map_by_cluster(db, time_series_df_with_labels)
        
        # Plotar gr√°fico comparativo de centr√≥ides
        plot_centroids_comparison(time_series_df.copy(), labels, model)
        
        # Plotar s√©ries temporais por cluster (com centr√≥ides)
        plot_time_series_by_cluster(time_series_df.copy(), labels, model)

        # Tabela com regi√£o
        st.markdown("#### Tabela de Munic√≠pios por Cluster")
        display_df = prepare_municipalities_table(
            time_series_df_with_labels, db)
        st.dataframe(display_df)

        # Usar dados j√° normalizados para silhouette (X_scaled_2d j√° foi calculado acima)
        plot_silhouette_by_cluster(X_scaled_2d, labels)
        
        # Exibir tabela de munic√≠pios removidos (se houver)
        removed_cities = cleaning_stats.get('removed_cities', [])
        if removed_cities:
            st.markdown("#### üóëÔ∏è Munic√≠pios Removidos (S√©ries Nulas)")
            st.markdown(f"**Total:** {len(removed_cities)} munic√≠pios foram removidos por terem s√©ries temporais completamente nulas.")
            
            # Buscar regi√µes dos munic√≠pios removidos
            try:
                query_removed = '''
                    SELECT m.nome, r.nome as regiao
                    FROM municipios m
                    LEFT JOIN regioes r ON m.regiao_id = r.id
                    WHERE m.nome = ANY(%s)
                    ORDER BY r.nome, m.nome;
                '''
                removed_df = db.fetch_df(
                    query_removed, 
                    (removed_cities,), 
                    columns=['Munic√≠pio', 'Regi√£o']
                )
                
                if not removed_df.empty:
                    st.dataframe(
                        removed_df,
                        width='stretch',
                        hide_index=True
                    )
                else:
                    # Fallback: mostrar apenas os nomes se n√£o encontrar no banco
                    fallback_df = pd.DataFrame({
                        'Munic√≠pio': removed_cities,
                        'Regi√£o': ['N/A'] * len(removed_cities)
                    })
                    st.dataframe(
                        fallback_df,
                        width='stretch',
                        hide_index=True
                    )
            except Exception as e:
                logger.warning(f"Erro ao buscar regi√µes dos munic√≠pios removidos: {e}")
                # Fallback em caso de erro
                fallback_df = pd.DataFrame({
                    'Munic√≠pio': removed_cities,
                    'Regi√£o': ['N/A'] * len(removed_cities)
                })
                st.dataframe(
                    fallback_df,
                    width='stretch',
                    hide_index=True
                )


def handle_pending_processing_model(status):
    """Gerencia o fluxo quando um modelo est√° pendente ou processando."""
    st.info(
        f"Uma solicita√ß√£o para este modelo j√° existe e est√° com o status: **{status}**.")
    st.write("A p√°gina vai atualizar automaticamente quando estiver conclu√≠do. Por favor, aguarde.")

    time.sleep(10)

    # Ativar flag para usar TTL baixo na pr√≥xima verifica√ß√£o
    st.session_state.force_refresh_models = True

    # Cache ser√° limpo automaticamente quando o status for atualizado
    st.rerun()


def handle_failed_model(selected_method, selected_solicit, params_k, params_d, db):
    """Gerencia o fluxo quando um modelo falhou."""
    err = selected_solicit.get('mensagem_erro')
    st.error(f"A √∫ltima tentativa de gerar este modelo falhou: {err}")

    # Se a mensagem de falha indica artefato ausente, oferece regenera√ß√£o
    # Atualizado para reconhecer a nova mensagem de erro
    if err and ('n√£o encontrado' in err or 'ausente' in err or 'banco de dados' in err):
        st.warning(
            "O artefato associado a esta solicita√ß√£o est√° ausente. Deseja regenerar?")
        if st.button("Regenerar modelo"):
            nova_id = db.create_solicitacao(
                params_k if selected_method == 'kmeans' else params_d)
            if nova_id:
                st.success(
                    f"Solicita√ß√£o de regenera√ß√£o criada (ID: {nova_id}).")
                # Cache √© limpo automaticamente pela fun√ß√£o create_solicitacao
                st.rerun()
            else:
                st.error("N√£o foi poss√≠vel criar a solicita√ß√£o de regenera√ß√£o.")
    else:
        if st.button("Tentar novamente"):
            nova_id = db.create_solicitacao(
                params_k if selected_method == 'kmeans' else params_d)
            if nova_id:
                st.success(
                    f"Nova solicita√ß√£o criada com sucesso (ID: {nova_id}). O modelo ser√° treinado em segundo plano.")
                # Cache √© limpo automaticamente pela fun√ß√£o create_solicitacao
                st.rerun()
            else:
                st.error(
                    "N√£o foi poss√≠vel criar uma nova solicita√ß√£o. Verifique se os par√¢metros j√° n√£o est√£o pendentes.")


def handle_expired_model(selected_method, params_k, params_d, db):
    """Gerencia o fluxo quando um modelo expirou."""
    st.warning(
        "Esta solicita√ß√£o expirou. Voc√™ pode reativ√°-la para que o modelo seja reprocessado.")
    if st.button("Reativar solicita√ß√£o"):
        nova_id = db.create_solicitacao(
            params_k if selected_method == 'kmeans' else params_d)
        if nova_id:
            st.success(f"Solicita√ß√£o reativada/confirmada (ID: {nova_id}).")
            # Cache √© limpo automaticamente pela fun√ß√£o create_solicitacao
            st.rerun()
        else:
            st.error(
                "N√£o foi poss√≠vel reativar a solicita√ß√£o. Verifique os par√¢metros e tente novamente.")


def handle_no_existing_models(params_k, params_d, db):
    """Gerencia o fluxo quando n√£o h√° modelos existentes."""
    st.warning("Nenhum modelo encontrado com os par√¢metros selecionados. Ser√° criada uma solicita√ß√£o para ambos os m√©todos: K-Means e K-DBA.")

    with st.form("form_confirmacao"):
        st.write("Deseja solicitar a cria√ß√£o de novos modelos (K-Means e K-DBA) com estes par√¢metros? O processo pode levar alguns minutos.")
        submitted = st.form_submit_button("Sim, criar solicita√ß√µes")

        if submitted:
            logger.info(
                f"Criando solicita√ß√µes para K-Means e K-DBA com par√¢metros: {params_k}")
            id_k = db.create_solicitacao(params_k)
            id_d = db.create_solicitacao(params_d)
            msgs = []
            if id_k:
                msgs.append(f"K-Means criada (ID: {id_k})")
                logger.info(f"Solicita√ß√£o K-Means criada com ID: {id_k}")
            else:
                msgs.append("K-Means n√£o criada (pode j√° existir)")
                logger.warning("Solicita√ß√£o K-Means n√£o foi criada")
            if id_d:
                msgs.append(f"K-DBA criada (ID: {id_d})")
                logger.info(f"Solicita√ß√£o K-DBA criada com ID: {id_d}")
            else:
                msgs.append("K-DBA n√£o criada (pode j√° existir)")
                logger.warning("Solicita√ß√£o K-DBA n√£o foi criada")
            st.success("; ".join(msgs))

            # Cache √© limpo automaticamente pela fun√ß√£o create_solicitacao
            # Pequena pausa para garantir que as opera√ß√µes sejam processadas
            time.sleep(1)
            logger.info("Executando rerun ap√≥s cria√ß√£o de solicita√ß√µes")
            st.rerun()


# ==================== HANDLERS CACHEADOS ====================

def handle_no_existing_models_cached(params_k, params_d):
    """Vers√£o otimizada com cache para quando n√£o h√° modelos existentes."""
    from utils.data.connection import DatabaseConnection

    logger.info("Processando nova solicita√ß√£o de modelo")
    with DatabaseConnection() as db:
        handle_no_existing_models(params_k, params_d, db)


def process_model_by_status(selected_method, selected_solicit, params, params_k, params_d):
    """Processa o modelo baseado no status da solicita√ß√£o."""
    from utils.data.connection import DatabaseConnection

    status = selected_solicit['status'] if selected_solicit else None

    # Usar conex√£o com banco para todas as opera√ß√µes
    with DatabaseConnection() as db:
        if status == 'CONCLUIDO':
            handle_completed_model(
                selected_method, selected_solicit, params, db)
        elif status in ['PENDENTE', 'PROCESSANDO']:
            handle_pending_processing_model(status)
        elif status == 'FALHOU':
            handle_failed_model(
                selected_method, selected_solicit, params_k, params_d, db)
        elif status == 'EXPIRADO':
            handle_expired_model(selected_method, params_k, params_d, db)
        else:
            logger.warning(f"Status desconhecido: {status}")
